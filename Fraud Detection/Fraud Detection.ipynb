{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abbe3535",
   "metadata": {},
   "source": [
    "## Hackathon Case Description - Fraud Detection\n",
    "Fraud in the banking industry can result in significant financial losses for banks and their customers. This data project aims to develop innovative fraud detection solutions for the banking industry to help banks detect and prevent fraud in real-time.\n",
    "\n",
    "\n",
    "### 1. Dataset Description \n",
    "| Variable | Description | Categorical or Numeric | Range | Inclusion or Exclusion | Transformation |\n",
    "| :-       | :-          | :-                     |  :-   | :-                     | :-             |\n",
    "| Step | The time or chronological order of each transaction. The range of values from 0 to 179 suggests that there are 180 unique steps or time periods in the dataset. A step value of 0 means the start of the data collection period or the beginning of the day, while a step value of 179 means the end of the data collection period or the end of the day. | Numeric | from 0 to 179 | Inclusion | No |\n",
    "| Customer | The unique identifier for each customer. | Categorical | N/A | Inclusion | Yes |\n",
    "| Age | Different age groups of the customers. The values of 0-6 may correspond to different age groups. A value of 0 means the age < 18, a value of 1 means the age 18-24, and U means unknown or unspecified. | Numerical | N/A | Inclusion | No |\n",
    "| Gender | The gender of the customers. M means male and F means female. | Categorical | N/A | Inclusion | Yes |\n",
    "| ZipcodeOri | The zip code information of the customers.| Numeric | N/A | Exclusion | N/A |\n",
    "| Merchant | The unique identifier for each merchant.| Categorical | N/A | Inclusion | Yes |\n",
    "| zipMerchant | The zip code information of the merchant.| Numeric | N/A | Exclusion | N/A |\n",
    "| category | The category of the transaction.| Categorical | N/A | Inclusion | Yes |\n",
    "| Amount | The amount of the transaction.| Numeric | from 0 to 6888.3 | Inclusion | No |\n",
    "| Fraud | A binary indicator of whether the transaction is fraudulent. 1 means yes and 0 means no.| Categorical | N/A | Inclusion | No |\n",
    "\n",
    "<br>\n",
    "The table above provides a summary of the dataset, outlining the description and categorization (categorical or numeric) of each variable, any relevant range information for numeric variables, whether the variable should be included or excluded for the model, and if included, whether any transformation is needed. Note that the variables of zipcodeOri and zipMerchant will be excluded from the analysis. This is due to the observation that all values within these variables are identical (i.e. 28007), suggesting that all transactions were conducted at the same location. It is therefore deemed unnecessary to include these two variables in the model for the purpose of our analysis. <br>\n",
    "\n",
    "<br>\n",
    "Below is an overview of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475a78a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>customer</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>zipcodeOri</th>\n",
       "      <th>merchant</th>\n",
       "      <th>zipMerchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>'C1093826151'</td>\n",
       "      <td>'4'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>'C352968107'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>39.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>'C2054744914'</td>\n",
       "      <td>'4'</td>\n",
       "      <td>'F'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M1823072687'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>26.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>'C1760612790'</td>\n",
       "      <td>'3'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>17.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>'C757503768'</td>\n",
       "      <td>'5'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>35.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step       customer  age gender zipcodeOri       merchant zipMerchant  \\\n",
       "0     0  'C1093826151'  '4'    'M'    '28007'   'M348934600'     '28007'   \n",
       "1     0   'C352968107'  '2'    'M'    '28007'   'M348934600'     '28007'   \n",
       "2     0  'C2054744914'  '4'    'F'    '28007'  'M1823072687'     '28007'   \n",
       "3     0  'C1760612790'  '3'    'M'    '28007'   'M348934600'     '28007'   \n",
       "4     0   'C757503768'  '5'    'M'    '28007'   'M348934600'     '28007'   \n",
       "\n",
       "              category  amount  fraud  \n",
       "0  'es_transportation'    4.55      0  \n",
       "1  'es_transportation'   39.68      0  \n",
       "2  'es_transportation'   26.89      0  \n",
       "3  'es_transportation'   17.25      0  \n",
       "4  'es_transportation'   35.72      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r'C:\\Users\\madlin\\Desktop\\les notes de madeline\\mademoiselle madeline stuff boooom\\DS\\Hackathon\\fraud.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a505aa22",
   "metadata": {},
   "source": [
    "### 2. Data Preparation\n",
    "#### 2.1. Data Cleaning\n",
    "After a thorough review of the dataset, it was found that there are no outliers, missing values or other anomalies present in the data. As a result, it has been determined that no data cleaning steps are necessary at this time.\n",
    "\n",
    "#### 2.2. Data Transformation\n",
    "The data transformations for categorical variables are needed. \n",
    "\n",
    "#### 2.3. Data Modeling\n",
    "\n",
    "Based on the nature of the dataset, logistic regression, decision tree and random forest modeling techniques are appropriate for fraud detection.\n",
    "\n",
    "##### 2.3.1. Logistic Model\n",
    "Logistics regression is a statistical method for binary classification problems, where the response variable is categorical with only two classes, for example, fraud or not fraud. The logistic regression model works by estimating the probability that an observation belongs to one class or another based on a set of predictor variables. In our case, the logistic regression model can estimate the probability of an event being fraudulet or not based on a set of features such as the time of the trasaction, customer, the identity of the customer, age of the customer, gender of the customer, the category of the transaction, amount of the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7307bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    117512\n",
      "           1       0.84      0.54      0.65      1417\n",
      "\n",
      "    accuracy                           0.99    118929\n",
      "   macro avg       0.92      0.77      0.83    118929\n",
      "weighted avg       0.99      0.99      0.99    118929\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madlin\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label encode the categorical features\n",
    "le = LabelEncoder()\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# split the data into features (X) and target variable (Y)\n",
    "X = df.drop('fraud', axis=1)\n",
    "Y = df['fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model and fit it on the training data\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "# Predict the fraud labels for the testing data\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dea135",
   "metadata": {},
   "source": [
    "In terms of our logistic model, the steps are as follows. Firstly, the categorical variables (i.e. customer, gender, merchant, category) were converted into numerical form. Then, the data was split into the features *X* and the target variable *Y*, where *X* contains all columns except the fraud column and *Y* is the fraud column. After that, the dataset is divided into training and testing sets using the 8/2 rule. Then the logistic regression classifier is initialized and fitted on the training dataset. The trained model is used to predict the fraud on the test dataset. \n",
    "\n",
    "The results are shown in the above table. The logistic model we built achieved a precision of 0.99 for non-fraud cases and 0.84 for fraud cases, which indicates 99% of the predicted non-fraud cases and 84% of the predicted fraud cases were correct. However, while the recall for non-fraud cases is 1, the recall for fraud cases is 0.54, meaning that this logistic model only captures 54% of the actual positive cases. The F1-score is an armonic mean of precision and recall, providing a single metric to assess the overall performance of a classifier. The F1-score is 1 for non-fraud cases but 0.65 for fraud cases, suggesting a lower overall performance in predicting fraud cases due to a trade-off between precision and recall. Accuracy measures the overall correctness of the classifier, considering both true positive and true negative predictions. This logistic model achieved an accuracy of 0.99, indicating a high level of correct predictions for both fraud and non-fradu cases combined. The macro average calculates the average performance metrics (precision, recall, and F1-score) considering all cases. This logistic model has a macro average of precision 0.92, recall 0.77, and F1-score is 0.83. The weighted average calculates the performance metrics weighted by the support of each class, which is a measure taking the class imbalance into consideration. This logistic model has the weighted average of 0.99 for all precision, recall, and F1-score, indicating a high performance when considering the class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8c6f6",
   "metadata": {},
   "source": [
    "##### 2.3.2. Decision Tree Model\n",
    "Decision tree model is a predictive algorithm that employs a tree-like structure to classify transactions as either fraudulent or non-fraudulent based on input features. It starts with a root node representing the entire dataset and recursively splits the data into smaller subsets using different attribute conditions. Each internal node represents a splitting condition, while the leaf nodes represent the final classification outcomes. The model evaluates various features at each node to determine the best split that maximizes the separation between fraud and non-fraud instances. In our case, the decision tree model can classify an event being fraudulet or not based on a set of features such as the time of the trasaction, customer, the identity of the customer, age of the customer, gender of the customer, the category of the transaction, amount of the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc421842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    117512\n",
      "           1       0.76      0.76      0.76      1417\n",
      "\n",
      "    accuracy                           0.99    118929\n",
      "   macro avg       0.88      0.88      0.88    118929\n",
      "weighted avg       0.99      0.99      0.99    118929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label encode the categorical features\n",
    "le = LabelEncoder()\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# split the data into features (X) and target variable (Y)\n",
    "X = df.drop('fraud', axis=1)\n",
    "Y = df['fraud']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# initialize the decision tree model and fit it on the training data\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "# predict the fraud labels for the testing data\n",
    "Y_pred = dt.predict(X_test)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d368ecf",
   "metadata": {},
   "source": [
    "Similar approaches were conducted for decision tree model in terms of data transformation, data split, training/ test data set division.\n",
    "\n",
    "The results are shown in the above table. The decision tree model we built achieved a precision of 1.00 for non-fraud cases and 0.76 for fraud cases, which indicates perfectly detecting the non-fraud cases and 76% correctioness for predicted the fraud cases. Compared to logstic model, the recall for fraud cases improves to be 0.76, meaning that the decision tree model has a better performance in capturing the actual positive cases. The decison tree model has a F1-score of 1 for non-fraud cases and 0.76 for fraud cases, also outperforms the logistic model. This decision tree model achieved an accuracy of 0.99, which is the same as logistic model. This decision tree model has a macro average of precision 0.88, recall 0.88, and F1-score is 0.88, with lower precision but higher recall and F1-score compared to logistic model. The weighted average for decision tree model is the same as logistic model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e2bf7",
   "metadata": {},
   "source": [
    "##### 2.3.3. Random Forest Model\n",
    "Random Forest model is an ensemble learning approach that combines multiple decision trees to identify fraudulent transactions. By training on labeled data and considering various features such as customer details, merchant information, and transaction attributes, the model constructs a collection of decision trees. Each tree independently evaluates the features and contributes to the final prediction through majority voting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37381d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    117512\n",
      "           1       0.90      0.76      0.83      1417\n",
      "\n",
      "    accuracy                           1.00    118929\n",
      "   macro avg       0.95      0.88      0.91    118929\n",
      "weighted avg       1.00      1.00      1.00    118929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label encode the categorical features\n",
    "le = LabelEncoder()\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Split the data into features (X) and target variable (Y)\n",
    "X = df.drop('fraud', axis=1)\n",
    "Y = df['fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the random forest model and fit it on the training data\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "rfc.fit(X_train, Y_train)\n",
    "\n",
    "# Predict the fraud labels for the testing data\n",
    "Y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b6ac2",
   "metadata": {},
   "source": [
    "Similar approaches were conducted for logistic model and decision tree model.\n",
    "\n",
    "The results are shown in the above table. The decision tree model we built achieved a precision of 1.00 for non-fraud cases and 0.90 for fraud cases, which indicates perfectly detecting the non-fraud cases and 90% correctioness for predicted the fraud cases. The recall for fraud cases for random forest model is 0.76, same as decison tree model but outperforms the logistic model. The random forest model has a F1-score of 1 for non-fraud cases and 0.83 for fraud cases, outperforming both the decision tree model and the logistic model. This decision tree model achieved an accuracy of 1.00, outperforming both the decision tree model and logistic model. This random forest model has a macro average of precision 0.95, recall 0.88, and F1-score is 0.91, having better performance than both decision tree model and logistic model in terms of all three metrics. The weighted average for random forest model is 1 for precision, recall, and F1-score. Overall, we could observe that the random forest model has the overall best performance among three models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a60cc",
   "metadata": {},
   "source": [
    "### 3. Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9602f",
   "metadata": {},
   "source": [
    "Overall, logistic Regression offers interpretability and works well for linearly separable fraud patterns. However, it may struggle with complex nonlinear relationships. Decision Tree models provide interpretable rules and capture complex patterns but can be prone to overfitting. Random Forest models, an ensemble of Decision Trees, handle complex patterns, mitigate overfitting, and offer robust fraud detection capabilities. Considering their strengths, the Random Forest model is recommended for fraud detection due to its ability to handle complex fraud patterns while providing accurate predictions and feature importance analysis. In our case, based on the above results of all three models, we could see that random forest model has the best performance in predicting the fraud cases. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
